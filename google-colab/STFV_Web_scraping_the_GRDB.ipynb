{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJOaG05JdoNH"
      },
      "source": [
        "# STFV - Web scraping the GRDB\n",
        "\n",
        "## Useful links\n",
        "\n",
        "1. Graded Ring Database - Smooth toric Fano varieties search: http://www.grdb.co.uk/search/toricsmooth\n",
        "\n",
        "2. Stack Overflow - Selenium in Google Colab: https://stackoverflow.com/questions/51046454/how-can-we-use-selenium-webdriver-in-colab-research-google-com\n",
        "\n",
        "3. Tutorials Point - Python web scraping dynamic websites: https://www.tutorialspoint.com/python_web_scraping/python_web_scraping_dynamic_websites.htm\n",
        "\n",
        "4. Stack Overflow - Finding elements by class name (and CSS selector): https://stackoverflow.com/questions/30002313/selenium-finding-elements-by-class-name-in-python\n",
        "\n",
        "5. Selenium Python Docs - Locating elements: https://selenium-python.readthedocs.io/locating-elements.html\n",
        "\n",
        "## Install Selenium and import webdriver\n",
        "\n",
        "From [2]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kep3E6BQA3R",
        "outputId": "bc4579ff-5876-48aa-e107-1b0936d3318d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (4.5.0)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.22.0)\n",
            "Requirement already satisfied: urllib3[socks]~=1.26 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.26.12)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.7/dist-packages (from selenium) (2022.6.15)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.9.2)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (22.1.0)\n",
            "Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.10)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.0.0rc9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.7/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.1.1)\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 264 kB in 3s (101 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (105.0.5195.102-0ubuntu0.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: use options instead of chrome_options\n",
            "  if sys.path[0] == '':\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Web scraping"
      ],
      "metadata": {
        "id": "yFWfs5daxOCI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jeni7oqdP3iC"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from time import sleep\n",
        "\n",
        "# Function to sleep for t seconds and click all \"More details\" buttons, \n",
        "# as (*) occasionally fails\n",
        "def sleep_and_click_more_details_buttons(t):\n",
        "  sleep(t)\n",
        "  buttons = wd.find_elements(By.CSS_SELECTOR, \"li[title='More details']\")\n",
        "  for b in buttons:\n",
        "    # The following line increases the script's robustness (*)\n",
        "    WebDriverWait(wd, 100).until(EC.element_to_be_clickable(b)).click()\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "  # Get website\n",
        "  wd.get(\"http://www.grdb.co.uk/search/toricsmooth\")\n",
        "  wd.implicitly_wait(100)\n",
        "  wd.maximize_window()\n",
        "\n",
        "  # Open output file\n",
        "  f = open(\"out.txt\", \"a\")\n",
        "\n",
        "  # For each page, try to click all \"More details\" buttons with increasing \n",
        "  # sleep times\n",
        "  for i in range(864):\n",
        "    try:\n",
        "      sleep_and_click_more_details_buttons(0)\n",
        "    except:\n",
        "      try:\n",
        "        sleep_and_click_more_details_buttons(4)\n",
        "      except:\n",
        "        try:\n",
        "          sleep_and_click_more_details_buttons(16)\n",
        "        except:\n",
        "          sleep_and_click_more_details_buttons(64)\n",
        "\n",
        "    # Find all polytopes on page and append data to file\n",
        "    for j in range(10):\n",
        "      id = i*10 + j + 1\n",
        "      if id < 8636:\n",
        "        eval_line = \"wd.find_element(By.ID, \\\"row\" + str(id) + \"\\\")\"\n",
        "        f.write(eval(eval_line).text)\n",
        "        f.write(\"\\n\\n\")\n",
        "    \n",
        "    # Go to next page\n",
        "    if i < 863:\n",
        "      go_to_button = wd.find_element(By.CSS_SELECTOR, \"li[title='Go to page \" + str(i + 2) + \"']\")\n",
        "      go_to_button.click()\n",
        "  \n",
        "  # Close output file\n",
        "  f.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Error correction"
      ],
      "metadata": {
        "id": "s2kbf93wxpWn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AY7r-1efQrPT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c69041e8-1ee4-44b1-9b48-dff06c193693"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Corrupt polytopes in first input file before execution: 21 \n",
            "\n",
            "Corrupt polytopes in output file after execution: \n",
            "\n",
            "Final corrupt polytope:\n",
            "7675\n",
            "Smooth toric Fano 6-fold X = X(Q) with degree (-KX)6 = 40320\n",
            "Vol(Q): 80\n",
            "#Vertices: 13\n",
            "#Facets: 80 \n",
            "\n",
            "# Corrupt polytopes in output file after execution:  1\n"
          ]
        }
      ],
      "source": [
        "# Open first input file and find initial corrupt polytopes\n",
        "f1 = open(\"in1.txt\", \"r\")\n",
        "polytope_strings1 = f1.read().split(\"\\n\\n\")\n",
        "f1.close()\n",
        "initial_corrupt_polytopes_indexes = []\n",
        "\n",
        "for i in range(len(polytope_strings1)):\n",
        "  if \"Dual\" not in polytope_strings1[i]:\n",
        "    initial_corrupt_polytopes_indexes.append(i)\n",
        "\n",
        "print(\"# Corrupt polytopes in first input file before execution:\", len(initial_corrupt_polytopes_indexes), \"\\n\")\n",
        "\n",
        "# Open second input file and replace corrupt polytopes\n",
        "f2 = open(\"in2.txt\", \"r\")\n",
        "polytope_strings2 = f2.read().split(\"\\n\\n\")\n",
        "f2.close()\n",
        "\n",
        "for i in initial_corrupt_polytopes_indexes:\n",
        "  if i < len(polytope_strings2) and \"Dual\" in polytope_strings2[i]:\n",
        "    polytope_strings1[i] = polytope_strings2[i]\n",
        "\n",
        "# Open and write output file, also count and print final corrupt polytopes\n",
        "print(\"Corrupt polytopes in output file after execution:\", \"\\n\")\n",
        "\n",
        "f3 = open(\"out.txt\", \"w\")\n",
        "final_corrupt_polytopes_count = 0\n",
        "\n",
        "for ps in polytope_strings1:\n",
        "  if \"Dual\" not in ps:\n",
        "    final_corrupt_polytopes_count += 1\n",
        "    print(ps, \"\\n\")\n",
        "  f3.write(ps + \"\\n\\n\")\n",
        "\n",
        "f3.close()\n",
        "print(\"# Corrupt polytopes in output file after execution:\", final_corrupt_polytopes_count)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parsing"
      ],
      "metadata": {
        "id": "JyFAlZqexxwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "# Function to parse a polytope string and assert its integrity\n",
        "def parse_polytope(string, index):\n",
        "  match = prog.match(string)\n",
        "  groups = match.groups()\n",
        "  assert(len(groups) == 11)\n",
        "  id = int(groups[0])\n",
        "  assert(id == index + 1)\n",
        "  centrally_symmetric = groups[1] == \"centrally symmetric \"\n",
        "  dim, deg = map(int, groups[2:4])\n",
        "  zero_barycentre = groups[4] == \"true\"\n",
        "  zero_dual_barycentre = groups[5] == \"true\"\n",
        "  vol, n_vertices, n_facets = map(int, groups[6:9])\n",
        "  parse_point = lambda s: list(map(int, s[1:-1].split(\",\")))\n",
        "  vertices = np.array(list(map(parse_point, groups[9].split(\", \"))))\n",
        "  assert n_vertices == np.shape(vertices)[0]\n",
        "  dual = np.array(list(map(parse_point, groups[10].split(\", \"))))\n",
        "  assert n_facets == np.shape(dual)[0]\n",
        "\n",
        "  # n_vertices and vertices have been transposed with n_facets and dual, respectively\n",
        "  return id, centrally_symmetric, dim, deg, zero_barycentre, zero_dual_barycentre, vol, n_facets, n_vertices, dual, vertices\n",
        "\n",
        "# Define and compile regular expression used to parse a polytope string\n",
        "pattern = r'''(\\d+)\n",
        "Smooth ([^\\n]+)?toric Fano (?:[^\\n]+) X = X\\(Q\\) with degree \\(-KX\\)(\\d+) = (\\d+)(?:\n",
        "Zero barycentre: (\\w+))?(?:\n",
        "Zero dual barycentre: (\\w+))?\n",
        "Vol\\(Q\\): (\\d+)\n",
        "#Vertices: (\\d+)\n",
        "#Facets: (\\d+)\n",
        "Vertices: ([^\\n]+)\n",
        "Dual: ([^\\n]+)'''\n",
        "prog = re.compile(pattern)\n",
        "\n",
        "# Loop through all polytope strings and parse them\n",
        "f = open(\"in.txt\", \"r\")\n",
        "polytope_strings = f.read().split(\"\\n\\n\")\n",
        "polytopes = []\n",
        "for i in range(len(polytope_strings)):\n",
        "  polytopes.append(parse_polytope(polytope_strings[i], i))\n",
        "\n",
        "# Save data as .npy binary file\n",
        "data = np.array(polytopes, dtype=object)\n",
        "np.save(\"data\", data)"
      ],
      "metadata": {
        "id": "hOm9wP7tx3Bv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}